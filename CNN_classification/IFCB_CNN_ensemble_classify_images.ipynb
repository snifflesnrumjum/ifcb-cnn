{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will use IFCB images to train a convolutional neural network and have it classify images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, ZeroPadding2D, Input\n",
    "from keras.layers import concatenate\n",
    "from keras.preprocessing import image as keras_image\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import tf as ktf\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Add, Multiply, Concatenate, Average\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "import skimage.transform as ski_transform\n",
    "import skimage.io as ski_io\n",
    "from skimage import img_as_float\n",
    "\n",
    "\n",
    "from PIL import Image as PIL_Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "import ROI_image_reader_stitched as ROI\n",
    "import shutil\n",
    "import pickle\n",
    "import ROI_image_reader_stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = 'F:/IFCB/'\n",
    "out_folder_of_images = home_path + 'Training_sets_padded/'  #path to the padded images from the training set\n",
    "out_folder_of_images_unpadded = home_path + 'Training_sets_unpadded/' #path to the unpadded images from the training set\n",
    "folder_of_images_validation = home_path + 'validation_sets/' #where to put the validation sets\n",
    "\n",
    "number_of_categories = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_background(image):\n",
    "    shape = image.shape\n",
    "    mid = int(shape[0] / 2)\n",
    "    bkgd_mean = image[mid,:].mean()\n",
    "    bkgd_std = image[mid, :].std()\n",
    "    image -= bkgd_mean\n",
    "    image /= (bkgd_std+0.001)\n",
    "    \n",
    "    image *= -1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image size\n",
    "image_size = 300  #an X by X size square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_models = '/path/to/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all three models if possible\n",
    "#combine them into one single ensemble model\n",
    "#make each individual model untrainable\n",
    "#train a final layer for weighting the individual models\n",
    "\n",
    "model1 = load_model(path_to_models + 'CNN_model_mdl1_padded.mdl')\n",
    "#model1.load_weights(path_to_models + 'CNN_model_weights_mdl1.wts')\n",
    "model1.trainable = False\n",
    "\n",
    "model2 = load_model(path_to_models + 'CNN_model_mdl2_padded.mdl')\n",
    "#model2.load_weights(path_to_models + 'CNN_model_weights_mdl2.wts')\n",
    "model2.trainable = False\n",
    "\n",
    "model3 = load_model(path_to_models + 'CNN_model_mdl3_padded.mdl')\n",
    "#model3.load_weights(path_to_models + 'CNN_model_weights_mdl3.wts')\n",
    "model3.trainable = False\n",
    "\n",
    "model4 = load_model(path_to_models + 'CNN_model_mdl1_unpadded.mdl')\n",
    "##model4.load_weights(path_to_models + 'CNN_model_weights_mdl3.wts')\n",
    "model4.trainable = False\n",
    "\n",
    "model5 = load_model(path_to_models + 'CNN_model_mdl2_unpadded.mdl')\n",
    "#model2.load_weights(path_to_models + 'CNN_model_weights_mdl2.wts')\n",
    "model5.trainable = False\n",
    "\n",
    "model6 = load_model(path_to_models + 'CNN_model_mdl3_unpadded.mdl')\n",
    "#model3.load_weights(path_to_models + 'CNN_model_weights_mdl3.wts')\n",
    "model6.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, layer in enumerate(model1.layers):\n",
    "    layer.name = 'Model1_'+str(num)\n",
    "model1.name = 'Model1'\n",
    "\n",
    "for num, layer in enumerate(model2.layers):\n",
    "    layer.name = 'Model2_'+str(num)\n",
    "model2.name =  'Model2'\n",
    "\n",
    "for num, layer in enumerate(model3.layers):\n",
    "    layer.name = 'Model3_'+str(num)\n",
    "model3.name = 'Model3'\n",
    "\n",
    "for num, layer in enumerate(model4.layers):\n",
    "    layer.name = 'Model4_'+str(num)\n",
    "model4.name = 'Model4'\n",
    "\n",
    "for num, layer in enumerate(model5.layers):\n",
    "    layer.name = 'Model5_'+str(num)\n",
    "model5.name =  'Model5'\n",
    "\n",
    "for num, layer in enumerate(model6.layers):\n",
    "    layer.name = 'Model6_'+str(num)\n",
    "model6.name = 'Model6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "padded_inputs = Input((image_size, image_size, 1))\n",
    "unpadded_inputs = Input((image_size, image_size, 1))\n",
    "\n",
    "out1 = model1(padded_inputs)\n",
    "out2 = model2(padded_inputs)\n",
    "out3 = model3(padded_inputs)\n",
    "#out4 = model4(common_inputs)\n",
    "out4 = model4(unpadded_inputs)\n",
    "out5 = model5(unpadded_inputs)\n",
    "out6 = model6(unpadded_inputs)\n",
    "\n",
    "test = Concatenate()([out1, out2, out3, out4, out5, out6])\n",
    "test = Dense(112, name='model_ensemble_3')(test)\n",
    "test = Activation('softmax', name='model_ensemble_4')(test)\n",
    "\n",
    "ensemble = Model([padded_inputs, unpadded_inputs], test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.00001, decay=.000001)\n",
    "ensemble.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_batches(num_batches=6795):\n",
    "    padded = []\n",
    "    unpadded = []\n",
    "    answers = []\n",
    "    for x in range(num_batches):\n",
    "        if x % 50 == 0:\n",
    "            print(x, end=',')\n",
    "        temp1 = photos.next()\n",
    "        temp2 = photos_unpadded.next()\n",
    "        padded.extend(temp1[0])\n",
    "        unpadded.extend(temp2[0])\n",
    "        answers.extend(temp1[1])\n",
    "    \n",
    "    return [padded, unpadded, answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_batch_generator():\n",
    "    \n",
    "    while 1:\n",
    "        temp1 = photos.next()\n",
    "        temp2 = photos_unpadded.next()\n",
    "        \n",
    "    \n",
    "        yield [[temp1[0], temp2[0]], temp1[1]]\n",
    "        \n",
    "    return\n",
    "\n",
    "def get_image_batch_generator_prediction():\n",
    "    \n",
    "    while 1:\n",
    "        temp1 = photos.next()\n",
    "        temp2 = photos_unpadded.next()\n",
    "        \n",
    "    \n",
    "        yield [temp1[0], temp2[0]]\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the ensemble model\n",
    "ensemble.load_weights(path_to_models + 'ensemble_model__weights.wts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# this version modified to classify images in a batch format (ideally 16 images at a time * 4 versions of each image)\n",
    "#this version modified to output class files\n",
    "#this version modified to use a different threshold for each category\n",
    "def classify_images_merged_pad_nopad(images, filename, outpath, class2use, cnn_model, generate_images=False, classification_threshold=None, pad_images=True):\n",
    "    image_results = {'TBscores':[],\n",
    "                     'roinum':[],\n",
    "                     'TBclass':[],\n",
    "                     'TBclass_above_threshold':[],\n",
    "                     'class2useTB':[],\n",
    "                     '__header__':'Python 3 Keras CNN',\n",
    "                     '__version__':'1.0',\n",
    "                     '__globals__':[]\n",
    "                    }\n",
    "    time1 = time.time()\n",
    "    if not classification_threshold:\n",
    "        classification_threshold = [0.38 for category in class2use]\n",
    "    elif len(classification_threshold) == 1:\n",
    "        temp_threshold = classification_threshold[0]\n",
    "        classification_threshold = [temp_threshold for category in class2use]\n",
    "        \n",
    "    num_images = len(images)\n",
    "    batch_size = 16\n",
    "    num_orientations = 2  # between 1-4 how many flips to the image for classifying it multiple ways \n",
    "    batches = int(num_images / batch_size) #how many batches to run\n",
    "    leftover_images = int(num_images % batch_size) #what the last batch size will be\n",
    "    img_num = 0\n",
    "    all_img_predictions = []\n",
    "    #create the batches\n",
    "    for batch in range(batches): #was for image in images\n",
    "        imgs_to_classify = []\n",
    "        imgs_to_classify_nopad = []\n",
    "        \n",
    "        for batch_image in range(batch_size):\n",
    "            #padded images\n",
    "            input_image = resize_image3(np.array(images[img_num][1]), pad_images=True)\n",
    "            input_image = eliminate_background(input_image)\n",
    "            input_image *= (1/255.) #classifier was trained using data that had been scaled to 0-1 from 0-255\n",
    "            imgs_to_classify.append(input_image)\n",
    "            if num_orientations > 1: \n",
    "                imgs_to_classify.append(input_image[::-1])\n",
    "                \n",
    "                if num_orientations > 2:\n",
    "                    imgs_to_classify.append(input_image[:,::-1])\n",
    "                    \n",
    "                    if num_orientations > 3:\n",
    "                        imgs_to_classify.append(input_image[::-1,::-1])\n",
    "            \n",
    "            #unpadded images\n",
    "            input_image = resize_image3(np.array(images[img_num][1]), pad_images=False)\n",
    "            input_image = eliminate_background(input_image)\n",
    "            input_image *= (1/255.) #classifier was trained using data that had been scaled to 0-1 from 0-255\n",
    "            imgs_to_classify_nopad.append(input_image)\n",
    "            if num_orientations > 1: \n",
    "                imgs_to_classify_nopad.append(input_image[::-1])\n",
    "                \n",
    "                if num_orientations > 2:\n",
    "                    imgs_to_classify_nopad.append(input_image[:,::-1])\n",
    "                    \n",
    "                    if num_orientations > 3:\n",
    "                        imgs_to_classify_nopad.append(input_image[::-1,::-1])\n",
    "            \n",
    "            img_num += 1\n",
    "        imgs_to_classify = np.array(imgs_to_classify).reshape(batch_size*num_orientations, 300, 300, 1)\n",
    "        imgs_to_classify_nopad = np.array(imgs_to_classify_nopad).reshape(batch_size*num_orientations, 300, 300, 1)\n",
    "\n",
    "        ##trying to predict in a batch instead of singly; this has [batch_size] images each of which is in two variations\n",
    "        probs = cnn_model.predict([imgs_to_classify, imgs_to_classify_nopad], batch_size=batch_size*num_orientations)\n",
    "        for prob in range(0,probs.shape[0],num_orientations):\n",
    "            all_img_predictions.append(probs[prob:prob+num_orientations].mean(axis=0).astype('float16'))\n",
    "        \n",
    "    #now do the remaining images if necessary\n",
    "    if leftover_images > 0:\n",
    "        imgs_to_classify = []\n",
    "        imgs_to_classify_nopad = []\n",
    "        \n",
    "        for batch_image in range(leftover_images):\n",
    "            #padded images\n",
    "            input_image = resize_image3(np.array(images[img_num][1]), pad_images=True)\n",
    "            input_image = eliminate_background(input_image)\n",
    "            input_image *= (1/255.) #classifier was trained using data that had been scaled to 0-1 from 0-255\n",
    "            imgs_to_classify.append(input_image)\n",
    "            if num_orientations > 1: \n",
    "                imgs_to_classify.append(input_image[::-1])\n",
    "                \n",
    "                if num_orientations > 2:\n",
    "                    imgs_to_classify.append(input_image[:,::-1])\n",
    "                    \n",
    "                    if num_orientations > 3:\n",
    "                        imgs_to_classify.append(input_image[::-1,::-1])\n",
    "            \n",
    "            #unpadded images\n",
    "            input_image = resize_image3(np.array(images[img_num][1]), pad_images=False)\n",
    "            input_image = eliminate_background(input_image)\n",
    "            input_image *= (1/255.) #classifier was trained using data that had been scaled to 0-1 from 0-255\n",
    "            imgs_to_classify_nopad.append(input_image)\n",
    "            if num_orientations > 1: \n",
    "                imgs_to_classify_nopad.append(input_image[::-1])\n",
    "                \n",
    "                if num_orientations > 2:\n",
    "                    imgs_to_classify_nopad.append(input_image[:,::-1])\n",
    "                    \n",
    "                    if num_orientations > 3:\n",
    "                        imgs_to_classify_nopad.append(input_image[::-1,::-1])\n",
    "            \n",
    "            \n",
    "            img_num += 1\n",
    "\n",
    "        imgs_to_classify = np.array(imgs_to_classify).reshape(leftover_images*num_orientations, 300, 300, 1)\n",
    "        imgs_to_classify_nopad = np.array(imgs_to_classify_nopad).reshape(leftover_images*num_orientations, 300, 300, 1)\n",
    "\n",
    "            ##trying to predict in a batch instead of singly; this has [batch_size] images each of which is in four variations\n",
    "        probs = cnn_model.predict([imgs_to_classify, imgs_to_classify_nopad], batch_size=leftover_images)\n",
    "        for prob in range(0,probs.shape[0],num_orientations):\n",
    "            all_img_predictions.append(probs[prob:prob+num_orientations].mean(axis=0).astype('float16'))\n",
    "    \n",
    "    #classification through network is complete\n",
    "    time2 = time.time()\n",
    "    img_num = 0\n",
    "    for img_prob in all_img_predictions:\n",
    "        predicted = class2use[np.argmax(img_prob)] #where does check_answer come in; replace with class2use\n",
    "        #add the general information to the class file\n",
    "        image_results['roinum'].append([images[img_num][0]])\n",
    "        image_results['TBscores'].append(img_prob)\n",
    "        image_results['TBclass'].append([np.array(predicted)])\n",
    "        if img_prob.max() >= classification_threshold[np.argmax(img_prob)]:\n",
    "            image_results['TBclass_above_threshold'].append([np.array(predicted)])\n",
    "            if generate_images:\n",
    "                ski_io.imsave('{0}{1}/{2}_{3:05d}.png'.format(out_folder_of_clustered_images, predicted, filename, images[img_num][0]), np.array(images[img_num][1]))\n",
    "                \n",
    "        else:\n",
    "            image_results['TBclass_above_threshold'].append([np.array('unclassified')])\n",
    "            if generate_images:\n",
    "                ski_io.imsave('{0}{1}/{2}_{3:05d}.png'.format(out_folder_of_clustered_images, 'unclassified' ,filename, images[img_num][0]), np.array(images[img_num][1]))\n",
    "        img_num += 1\n",
    "        \n",
    "    time3 = time.time()    \n",
    "    ##code below should write the class file\n",
    "    image_results['TBscores'] = np.array(image_results['TBscores'])\n",
    "    image_results['TBclass_above_threshold'] = np.array(image_results['TBclass_above_threshold'])\n",
    "    \n",
    "    image_results['roinum'] = np.array(image_results['roinum']).astype('uint16')\n",
    "    temp_class = np.empty((len(image_results['TBclass']),), object)\n",
    "    temp_class_threshold = np.empty((len(image_results['TBclass_above_threshold']),), object)\n",
    "    for img in range(len(temp_class)):\n",
    "        temp_class[img] = image_results['TBclass'][img][0]\n",
    "        temp_class_threshold[img] = image_results['TBclass_above_threshold'][img][0]\n",
    "    image_results['TBclass'] = temp_class\n",
    "    image_results['TBclass_above_threshold'] = temp_class_threshold\n",
    "    #create the class2use variable\n",
    "    temp_class2use = np.empty((len(class2use),), object)\n",
    "    for ind_class in range(len(class2use)):\n",
    "        temp_class2use[ind_class] = np.array(class2use[ind_class])\n",
    "    image_results['class2useTB'] = temp_class2use\n",
    "    savemat(outpath+filename+'_class_vCNN1.mat', image_results, do_compression=True)\n",
    "    \n",
    "    time4 = time.time()\n",
    "    print()\n",
    "    print('Classification:  ', time2-time1)\n",
    "    print('Thresholding:    ', time3-time2)\n",
    "    print('Write class file:', time4-time3)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the probability results in case we want to change our threshold later\n",
    "with open('/path/to/models/thresholds_ensemble.pck', 'rb') as f:\n",
    "    thresholds = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(check_answer[x], thresholds[x]) for x in range(112)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new function to mimic how the training set images were resized and centered\n",
    "def resize_image3(temp_image, pad_images=True):\n",
    "    image_size = 300\n",
    "    temp_shape = temp_image.shape\n",
    "    bkgd_mean = temp_image[0,:].mean()\n",
    "    if pad_images:\n",
    "        if temp_image.shape[0] != temp_image.shape[1]:\n",
    "            if temp_image.shape[0] > image_size or temp_image.shape[1] > image_size:\n",
    "                new_image = np.full((max(temp_image.shape), max(temp_image.shape)), bkgd_mean)\n",
    "            else:\n",
    "                new_image = np.full((image_size, image_size), bkgd_mean)\n",
    "            new_shape = new_image.shape\n",
    "            center = np.array(new_shape) - np.array(temp_image.shape)\n",
    "            new_image[int(center[0]/2):(int(center[0]/2) + temp_shape[0]), int(center[1]/2):(int(center[1]/2) + temp_shape[1])] = temp_image           \n",
    "        else:\n",
    "            new_image = ski_transform.resize(temp_image, (image_size, image_size))\n",
    "        if new_image.shape[0] > image_size:\n",
    "            new_image = ski_transform.resize(new_image, (image_size, image_size))\n",
    "    else:\n",
    "        new_image = ski_transform.resize(temp_image, (image_size, image_size))\n",
    "    #print('new_image = '+str(new_image))\n",
    "    return img_as_float(new_image)# * (1/255.))\n",
    "\n",
    "def load_IFCB_file(filename, datapath):\n",
    "    images = ROI_image_reader_stitched.process_file(datapath+filename)\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the folders in the out directory\n",
    "#add in an unclassified directory\n",
    "class2use_master_out = loadmat('/path/to/class2use_master/file/') #load the class2use_master file to get the class names\n",
    "class2use = [class2use_master_out['class2use'][0][x][0] for x in range(len(class2use_master_out['class2use'][0]))]\n",
    "\n",
    "#where should the image folders go?\n",
    "out_folder_of_clustered_images = '/path/to/out/images/'\n",
    "check_answer = sort(list(class2use))\n",
    "for x in check_answer:\n",
    "    os.mkdir(out_folder_of_clustered_images + str(x))\n",
    "if 'unclassified' not in check_answer:\n",
    "    os.mkdir(out_folder_of_clustered_images + 'unclassified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datapath = '/path/to/raw/IFCB/data/' #where are the ROI, HDR, ADC files?\n",
    "listofdirs = sort(os.listdir(datapath))\n",
    "outpath = '/path/to/class/files/' #where should the class_file outputs be placed?\n",
    "finished_files = os.listdir(outpath)\n",
    "for indir in listofdirs[::-1]:\n",
    "    if indir == 'beads': #skip the beads folder if present\n",
    "        continue\n",
    "    listoffiles_temp = os.listdir(datapath + indir)\n",
    "    listoffiles = sort(list(set([x[:-4] for x in listoffiles_temp])))\n",
    "    for filenum, datafile in enumerate(listoffiles[:]):\n",
    "        if datafile + '_class_CNNv1.mat' in finished_files:\n",
    "            continue\n",
    "        else:\n",
    "            print('Starting {0} {1}...loading file'.format(filenum, datafile), end='...')\n",
    "            try:\n",
    "                test_data = load_IFCB_file(datafile, datapath+indir+'/')\n",
    "                print('Num images:{0}'.format(len(test_data)))\n",
    "                print('classifying images', end='...')\n",
    "                classify_images_merged_pad_nopad(test_data, datafile, outpath, class2use, ensemble, generate_images=False,\n",
    "                                      classification_threshold=thresholds, pad_images=True)\n",
    "                print('done!')\n",
    "            except:\n",
    "                print('error occurred!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
