{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will use IFCB images to train a convolutional neural network and have it classify images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, ZeroPadding2D, Input\n",
    "from keras.layers import concatenate\n",
    "from keras.preprocessing import image as keras_image\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import tf as ktf\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Add, Multiply, Concatenate, Average\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "import skimage.transform as ski_transform\n",
    "import skimage.io as ski_io\n",
    "from skimage import img_as_float\n",
    "\n",
    "\n",
    "from PIL import Image as PIL_Image\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "import ROI_image_reader_stitched as ROI\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = 'F:/IFCB/'\n",
    "out_folder_of_images = home_path + 'Training_sets/'\n",
    "folder_of_images_validation = home_path + 'validation_sets/'\n",
    "number_of_categories = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_background(image):\n",
    "    shape = image.shape\n",
    "    mid = int(shape[0] / 2)\n",
    "    bkgd_mean = image[mid,:].mean()\n",
    "    bkgd_std = image[mid, :].std()\n",
    "    image -= bkgd_mean\n",
    "    image /= (bkgd_std+0.001)\n",
    "    \n",
    "    image *= -1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image size\n",
    "image_size = 300  #an X by X size square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move validation set back into main set\n",
    "photos = os.walk(folder_of_images_validation)\n",
    "\n",
    "for files in photos:\n",
    "    print(files[0])\n",
    "    outdir = files[0].split('/')[-1]\n",
    "    for picture in files[2]:\n",
    "        if picture[-3:] == 'png' or picture[-3:] == 'tif':\n",
    "            #print(picture)\n",
    "            shutil.move(files[0]+'/'+picture, out_folder_of_images + outdir + '/' + picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a validation dataset\n",
    "import shutil\n",
    "photos = os.walk(out_folder_of_images)\n",
    "\n",
    "num_photo = 0\n",
    "for files in photos:\n",
    "    print(files[0])\n",
    "    outdir = files[0].split('/')[-1]\n",
    "    if outdir not in os.listdir(folder_of_images_validation) and outdir != '':\n",
    "        os.mkdir('{0}/{1}'.format(folder_of_images_validation, outdir))\n",
    "    for picture in files[2][0::5]:\n",
    "        if picture[-3:] == 'png' or picture[-3:] == 'tif':\n",
    "            #print(picture)\n",
    "            num_photo += 1\n",
    "            shutil.move(files[0]+'/'+picture, folder_of_images_validation + outdir + '/' + picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training data generator\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos = keras_image.ImageDataGenerator(#rotation_range=10,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        horizontal_flip=True, #flip images horizontally\n",
    "                                        vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        #samplewise_std_normalization=True,\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.1,\n",
    "                                        #featurewise_center=True,\n",
    "                                        #featurewise_std_normalization=True\n",
    "                                       )\n",
    "\n",
    "#start the actual flow of images for training\n",
    "photos = input_photos.flow_from_directory(out_folder_of_images, \n",
    "                                          #shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          batch_size=16,) #how many images per batch\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#validation data generator\n",
    "\n",
    "\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos_validation = keras_image.ImageDataGenerator(#rotation_range=10,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        #width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        horizontal_flip=True, #flip images horizontally\n",
    "                                        vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation[constant, wrap, reflect, nearest]\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.1,\n",
    "                                        \n",
    "                                        )\n",
    "#start the actual flow of images for training\n",
    "photos_validation = input_photos_validation.flow_from_directory(folder_of_images_validation, \n",
    "                                          #shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          #save_to_dir='D:/Python27/Projects/Classifiers/augmented_data/',\n",
    "                                          batch_size=16) #how many images per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix data generator\n",
    "\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos_confusion = keras_image.ImageDataGenerator(#rotation_range=10.,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        #width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        #horizontal_flip=True, #flip images horizontally\n",
    "                                        #vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation[constant, wrap, reflect, nearest]\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.15,\n",
    "                                        )\n",
    "#start the actual flow of images for training\n",
    "photos_confusion = input_photos_confusion.flow_from_directory(out_folder_of_images, \n",
    "                                          shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          batch_size=16 #how many images per batch\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix data generator\n",
    "\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos_validation_confusion = keras_image.ImageDataGenerator(#rotation_range=10.,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        #width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        #horizontal_flip=True, #flip images horizontally\n",
    "                                        #vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation[constant, wrap, reflect, nearest]\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.15,\n",
    "                                        )\n",
    "#start the actual flow of images for training\n",
    "photos_validation_confusion = input_photos_confusion.flow_from_directory(folder_of_images_validation, \n",
    "                                          shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          batch_size=16 #how many images per batch\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Okay the images are all ready to be loaded and will be resized to a 300x300 image (I can change this in the #ImageDataGenerator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functional API version of the model\n",
    "#since Keras update broke the easy way of replacing model layers it seems more  prudent to use the functional way\n",
    "#instead of the sequential api\n",
    "\n",
    "inputs = Input((image_size, image_size, 1))\n",
    "conv1 = Conv2D(64, (7,7), padding='same', strides=3)(inputs)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "conv1 = Activation('relu')(conv1)\n",
    "conv1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(128, (3,3), padding='same', strides=1)(conv1)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Activation('relu')(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3,3), padding='same', strides=1)(conv2)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = Activation('relu')(conv3)\n",
    "\n",
    "conv_3a = Conv2D(32, (1,1), padding='same', strides=1, name='conv3a')(conv3)\n",
    "conv_3a = BatchNormalization()(conv_3a)\n",
    "\n",
    "conv_3b = Conv2D(128, (5,5), padding='same', name='conv_3b')(conv_3a)\n",
    "conv_3b = BatchNormalization()(conv_3b)\n",
    "conv_3b = Activation('relu')(conv_3b)\n",
    "conv_3b = MaxPooling2D(pool_size=(2,2))(conv_3b)\n",
    "\n",
    "conv_4a = Conv2D(32, (1,1), padding='same', strides=1, name='conv4a')(conv3)\n",
    "conv_4a = BatchNormalization()(conv_4a)\n",
    "\n",
    "conv_4b = Conv2D(128, (3,3), padding='same', name='conv_4b')(conv_4a)\n",
    "conv_4b = BatchNormalization()(conv_4b)\n",
    "conv_4b = Activation('relu')(conv_4b)\n",
    "conv_4b = MaxPooling2D(pool_size=(2,2))(conv_4b)\n",
    "\n",
    "conv4 = Conv2D(32, (1,1), padding='same')(conv3)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "conv4 = Activation('relu')(conv4)\n",
    "\n",
    "conv5 = Conv2D(128, (3,3), padding='same')(conv4)\n",
    "conv5 = BatchNormalization()(conv5)\n",
    "conv5 = Activation('relu')(conv5)\n",
    "conv5 = MaxPooling2D(pool_size=(2,2))(conv5)\n",
    "\n",
    "merged = concatenate([conv5, conv_3b, conv_4b])\n",
    "\n",
    "conv7 = Conv2D(256, (3,3), padding='same')(merged)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "conv7 = Activation('relu')(conv7)\n",
    "conv7 = MaxPooling2D(pool_size=(2,2))(conv7)\n",
    "\n",
    "conv9 = Conv2D(512, (3,3), padding='valid')(conv7)\n",
    "conv9 = BatchNormalization()(conv9)\n",
    "conv9 = Activation('relu')(conv9)\n",
    "conv9 = MaxPooling2D(pool_size=(2,2))(conv9)\n",
    "\n",
    "conv9 = Conv2D(1024, (3,3), padding='same')(conv9)\n",
    "conv9 = BatchNormalization()(conv9)\n",
    "conv9 = Activation('relu')(conv9)\n",
    "conv9 = MaxPooling2D(pool_size=(2,2))(conv9)\n",
    "\n",
    "flat = Flatten()(conv9)\n",
    "flat = Dense(1000)(flat)\n",
    "flat = Activation('relu')(flat)\n",
    "flat = Dropout(0.25)(flat)\n",
    "flat = Dense(250)(flat)\n",
    "flat = Activation('relu')(flat)\n",
    "\n",
    "\n",
    "finish = Dropout(0.25)(flat)\n",
    "finish = Dense(number_of_categories)(finish)\n",
    "finish = Activation('softmax')(finish)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[finish])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, decay=.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'],\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model.count_params())\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_images = len(photos.classes)\n",
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try this function to correct for imbalanced classes \n",
    "#downloaded this function from: https://github.com/cbaziotis/keras-utilities/blob/master/kutilities/helpers/data_preparation.py\n",
    "\n",
    "def get_class_weights(y, smooth_factor=0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    return {cls: float(majority) / count for cls, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_class_weights = get_class_weights(photos.classes, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(photos, \n",
    "                    #steps_per_epoch=200,\n",
    "                    steps_per_epoch=num_images/16,\n",
    "                    epochs=10,\n",
    "                    initial_epoch=0,\n",
    "                    validation_data = photos_validation,\n",
    "                    validation_steps = 600,\n",
    "                    class_weight=temp_class_weights,  #this is to help with the unbalanced class issue\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use these lines to save the model to a file; change the filename to whatever you want\n",
    "model.save('path/to/where/you/store/models/CNN_model_mdl1.mdl')\n",
    "\n",
    "#model weights are included in the model file itself so this isn't entirely necessary\n",
    "model.save_weights('path/to/where/you/store/model/weights/CNN_model_weights_mdl1.wts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you might see a lot of warning for this one, but it should load fine\n",
    "model = load_model(home_path + 'models/CNN_model_mdl1.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a confusion matrix based on the training data\n",
    "photos_confusion.reset()\n",
    "Y_pred = model.predict_generator(photos_confusion, num_images/16 + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "num_images = len(photos.classes)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(photos_confusion.classes, y_pred[:num_images]))\n",
    "check_answer = sort(list(photos_confusion.class_indices))\n",
    "print('Classification Report')\n",
    "target_names = check_answer\n",
    "print(classification_report(photos_confusion.classes, y_pred[:num_images], target_names=target_names))\n",
    "conf_mat = pd.DataFrame(confusion_matrix(photos_confusion.classes, y_pred[:num_images]), columns=target_names, index=target_names)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a heatmap of the confusion matrix\n",
    "figsize(20, 20)\n",
    "sns.heatmap(conf_mat.divide(conf_mat.sum()+1), vmax=1, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for validation data set\n",
    "photos_validation_confusion.reset()\n",
    "Y_pred = model.predict_generator(photos_validation_confusion, num_images/16 + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "num_images = len(photos_validation_confusion.classes)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(photos_validation_confusion.classes, y_pred[:num_images]))\n",
    "check_answer = sort(list(photos_validation_confusion.class_indices))\n",
    "print('Classification Report')\n",
    "target_names = check_answer\n",
    "print(classification_report(photos_validation_confusion.classes, y_pred[:num_images], target_names=target_names))\n",
    "conf_mat = pd.DataFrame(confusion_matrix(photos_validation_confusion.classes, y_pred[:num_images]), columns=target_names, index=target_names)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot heatmap of confusion matrix for validation data\n",
    "figsize(20, 20)\n",
    "sns.heatmap(conf_mat.divide(conf_mat.sum()+1), vmax=1, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move validation set back into main set before training next model\n",
    "photos = os.walk(folder_of_images_validation)\n",
    "\n",
    "for files in photos:\n",
    "    print(files[0])\n",
    "    outdir = files[0].split('/')[-1]\n",
    "    for picture in files[2]:\n",
    "        if picture[-3:] == 'png' or picture[-3:] == 'tif':\n",
    "            #print(picture)\n",
    "            shutil.move(files[0]+'/'+picture, out_folder_of_images + outdir + '/' + picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create a second validation dataset\n",
    "photos = os.walk(out_folder_of_images)\n",
    "num_photo = 0\n",
    "for files in photos:\n",
    "    print(files[0])\n",
    "    outdir = files[0].split('/')[-1]\n",
    "    if outdir not in os.listdir(folder_of_images_validation) and outdir != '':\n",
    "        os.mkdir('{0}/{1}'.format(folder_of_images_validation, outdir))\n",
    "    for picture in files[2][1::5]:\n",
    "        if picture[-3:] == 'png' or picture[-3:] == 'tif':\n",
    "            #print(picture)\n",
    "            num_photo += 1\n",
    "            shutil.move(files[0]+'/'+picture, folder_of_images_validation + outdir + '/' + picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training data generator\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos = keras_image.ImageDataGenerator(#rotation_range=10,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        horizontal_flip=True, #flip images horizontally\n",
    "                                        vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        #samplewise_std_normalization=True,\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.1,\n",
    "                                        #featurewise_center=True,\n",
    "                                        #featurewise_std_normalization=True\n",
    "                                       )\n",
    "\n",
    "#start the actual flow of images for training\n",
    "photos = input_photos.flow_from_directory(out_folder_of_images, \n",
    "                                          #shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          batch_size=16,) #how many images per batch\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#validation data generator\n",
    "\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos_validation = keras_image.ImageDataGenerator(#rotation_range=10,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        #width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        horizontal_flip=True, #flip images horizontally\n",
    "                                        vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation[constant, wrap, reflect, nearest]\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.1,\n",
    "                                        \n",
    "                                        )\n",
    "#start the actual flow of images for training\n",
    "photos_validation = input_photos_validation.flow_from_directory(folder_of_images_validation, \n",
    "                                          #shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          #save_to_dir='D:/Python27/Projects/Classifiers/augmented_data/',\n",
    "                                          batch_size=16) #how many images per batch\n",
    "\n",
    "\n",
    "#confusion_matrix data generator\n",
    "\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos_confusion = keras_image.ImageDataGenerator(#rotation_range=10.,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        #width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        #horizontal_flip=True, #flip images horizontally\n",
    "                                        #vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation[constant, wrap, reflect, nearest]\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.15,\n",
    "                                        )\n",
    "#start the actual flow of images for training\n",
    "photos_confusion = input_photos_confusion.flow_from_directory(out_folder_of_images, \n",
    "                                          shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          batch_size=16 #how many images per batch\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix data generator\n",
    "\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos_validation_confusion = keras_image.ImageDataGenerator(#rotation_range=10.,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        #width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        #horizontal_flip=True, #flip images horizontally\n",
    "                                        #vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation[constant, wrap, reflect, nearest]\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.15,\n",
    "                                        )\n",
    "#start the actual flow of images for training\n",
    "photos_validation_confusion = input_photos_confusion.flow_from_directory(folder_of_images_validation, \n",
    "                                          shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          batch_size=16 #how many images per batch\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functional API version of the model\n",
    "#since Keras update broke the easy way of replacing model layers it seems more  prudent to use the functional way\n",
    "#instead of the sequential api\n",
    "\n",
    "inputs = Input((image_size, image_size, 1))\n",
    "conv1 = Conv2D(64, (5,5), padding='same', strides=3)(inputs)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "conv1 = Activation('relu')(conv1)\n",
    "conv1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(128, (3,3), padding='same', strides=1)(conv1)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Activation('relu')(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3,3), padding='same', strides=1)(conv2)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = Activation('relu')(conv3)\n",
    "\n",
    "conv_3a = Conv2D(32, (1,1), padding='same', strides=1, name='conv3a')(conv3)\n",
    "conv_3a = BatchNormalization()(conv_3a)\n",
    "\n",
    "conv_3b = Conv2D(128, (5,5), padding='same', name='conv_3b')(conv_3a)\n",
    "conv_3b = BatchNormalization()(conv_3b)\n",
    "conv_3b = Activation('relu')(conv_3b)\n",
    "conv_3b = MaxPooling2D(pool_size=(2,2))(conv_3b)\n",
    "\n",
    "conv_4a = Conv2D(32, (1,1), padding='same', strides=1, name='conv4a')(conv3)\n",
    "conv_4a = BatchNormalization()(conv_4a)\n",
    "\n",
    "conv_4b = Conv2D(128, (3,3), padding='same', name='conv_4b')(conv_4a)\n",
    "conv_4b = BatchNormalization()(conv_4b)\n",
    "conv_4b = Activation('relu')(conv_4b)\n",
    "conv_4b = MaxPooling2D(pool_size=(2,2))(conv_4b)\n",
    "\n",
    "conv4 = Conv2D(32, (1,1), padding='same')(conv3)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "conv4 = Activation('relu')(conv4)\n",
    "\n",
    "conv5 = Conv2D(128, (3,3), padding='same')(conv4)\n",
    "conv5 = BatchNormalization()(conv5)\n",
    "conv5 = Activation('relu')(conv5)\n",
    "conv5 = MaxPooling2D(pool_size=(2,2))(conv5)\n",
    "\n",
    "merged = concatenate([conv5, conv_3b, conv_4b])\n",
    "\n",
    "conv7 = Conv2D(256, (3,3), padding='same')(merged)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "conv7 = Activation('relu')(conv7)\n",
    "conv7 = MaxPooling2D(pool_size=(2,2))(conv7)\n",
    "\n",
    "conv9 = Conv2D(512, (3,3), padding='valid')(conv7)\n",
    "conv9 = BatchNormalization()(conv9)\n",
    "conv9 = Activation('relu')(conv9)\n",
    "conv9 = MaxPooling2D(pool_size=(2,2))(conv9)\n",
    "\n",
    "conv9 = Conv2D(1024, (3,3), padding='same')(conv9)\n",
    "conv9 = BatchNormalization()(conv9)\n",
    "conv9 = Activation('relu')(conv9)\n",
    "conv9 = MaxPooling2D(pool_size=(2,2))(conv9)\n",
    "#conv9 = MaxPooling2D(pool_size=(2,2))(conv9)\n",
    "\n",
    "flat = Flatten()(conv9)\n",
    "flat = Dense(1000)(flat)\n",
    "flat = Activation('relu')(flat)\n",
    "flat = Dropout(0.25)(flat)\n",
    "flat = Dense(250)(flat)\n",
    "flat = Activation('relu')(flat)\n",
    "\n",
    "\n",
    "finish = Dropout(0.25)(flat)\n",
    "finish = Dense(number_of_categories)(finish)\n",
    "finish = Activation('softmax')(finish)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[finish])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, decay=.00001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "print(model.count_params())\n",
    "print(model.summary())\n",
    "\n",
    "temp_class_weights = get_class_weights(photos.classes, 0.1)\n",
    "num_images = len(photos.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(photos, \n",
    "                    #steps_per_epoch=200,\n",
    "                    steps_per_epoch=num_images/16,\n",
    "                    epochs=10,\n",
    "                    initial_epoch=0,\n",
    "                    validation_data = photos_validation,\n",
    "                    validation_steps = 600,\n",
    "                    class_weight=temp_class_weights,  #this is to help with the unbalanced class issue\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('path/to/models/CNN_model_mdl2.mdl')\n",
    "model.save_weights('path/to/weights/CNN_model_weights_mdl2.wts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(home_path + 'models/CNN_model_mdl2.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "photos_confusion.reset()\n",
    "Y_pred = model.predict_generator(photos_confusion, num_images/16 + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "num_images = len(photos_confusion.classes)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(photos_confusion.classes, y_pred[:num_images]))\n",
    "check_answer = sort(list(photos_confusion.class_indices))\n",
    "print('Classification Report')\n",
    "target_names = check_answer\n",
    "print(classification_report(photos_confusion.classes, y_pred[:num_images], target_names=target_names))\n",
    "conf_mat = pd.DataFrame(confusion_matrix(photos_confusion.classes, y_pred[:num_images]), columns=target_names, index=target_names)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figsize(20, 20)\n",
    "sns.heatmap(conf_mat.divide(conf_mat.sum()+1), vmax=1, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_validation_confusion.reset()\n",
    "Y_pred = model.predict_generator(photos_validation_confusion, num_images/16 + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "num_images = len(photos_validation_confusion.classes)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(photos_validation_confusion.classes, y_pred[:num_images]))\n",
    "check_answer = sort(list(photos_validation_confusion.class_indices))\n",
    "print('Classification Report')\n",
    "target_names = check_answer\n",
    "print(classification_report(photos_validation_confusion.classes, y_pred[:num_images], target_names=target_names))\n",
    "conf_mat = pd.DataFrame(confusion_matrix(photos_validation_confusion.classes, y_pred[:num_images]), columns=target_names, index=target_names)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figsize(20, 20)\n",
    "sns.heatmap(conf_mat.divide(conf_mat.sum()+1), vmax=1, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#move validation set back into main set\n",
    "photos = os.walk(folder_of_images_validation)\n",
    "\n",
    "for files in photos:\n",
    "    print(files[0])\n",
    "    outdir = files[0].split('/')[-1]\n",
    "    for picture in files[2]:\n",
    "        if picture[-3:] == 'png' or picture[-3:] == 'tif':\n",
    "            #print(picture)\n",
    "            shutil.move(files[0]+'/'+picture, out_folder_of_images + outdir + '/' + picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a validation dataset\n",
    "import shutil\n",
    "photos = os.walk(out_folder_of_images)\n",
    "\n",
    "num_photo = 0\n",
    "for files in photos:\n",
    "    print(files[0])\n",
    "    outdir = files[0].split('/')[-1]\n",
    "    if outdir not in os.listdir(folder_of_images_validation) and outdir != '':\n",
    "        os.mkdir('{0}/{1}'.format(folder_of_images_validation, outdir))\n",
    "    for picture in files[2][2::5]:\n",
    "        if picture[-3:] == 'png' or picture[-3:] == 'tif':\n",
    "            #print(picture)\n",
    "            num_photo += 1\n",
    "            shutil.move(files[0]+'/'+picture, folder_of_images_validation + outdir + '/' + picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training data generator\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos = keras_image.ImageDataGenerator(#rotation_range=10,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        horizontal_flip=True, #flip images horizontally\n",
    "                                        vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        #samplewise_std_normalization=True,\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.1,\n",
    "                                        #featurewise_center=True,\n",
    "                                        #featurewise_std_normalization=True\n",
    "                                       )\n",
    "\n",
    "#start the actual flow of images for training\n",
    "photos = input_photos.flow_from_directory(out_folder_of_images, \n",
    "                                          #shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          batch_size=16,) #how many images per batch\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#validation data generator\n",
    "\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos_validation = keras_image.ImageDataGenerator(#rotation_range=10,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        #width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        horizontal_flip=True, #flip images horizontally\n",
    "                                        vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation[constant, wrap, reflect, nearest]\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.1,\n",
    "                                        \n",
    "                                        )\n",
    "#start the actual flow of images for training\n",
    "photos_validation = input_photos_validation.flow_from_directory(folder_of_images_validation, \n",
    "                                          #shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          #save_to_dir='D:/Python27/Projects/Classifiers/augmented_data/',\n",
    "                                          batch_size=16) #how many images per batch\n",
    "\n",
    "\n",
    "#confusion_matrix data generator\n",
    "\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos_confusion = keras_image.ImageDataGenerator(#rotation_range=10.,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        #width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        #horizontal_flip=True, #flip images horizontally\n",
    "                                        #vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation[constant, wrap, reflect, nearest]\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.15,\n",
    "                                        )\n",
    "#start the actual flow of images for training\n",
    "photos_confusion = input_photos_confusion.flow_from_directory(out_folder_of_images, \n",
    "                                          shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          batch_size=16 #how many images per batch\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix data generator\n",
    "\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos_validation_confusion = keras_image.ImageDataGenerator(#rotation_range=10.,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        #width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        #horizontal_flip=True, #flip images horizontally\n",
    "                                        #vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation[constant, wrap, reflect, nearest]\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.15,\n",
    "                                        )\n",
    "#start the actual flow of images for training\n",
    "photos_validation_confusion = input_photos_confusion.flow_from_directory(folder_of_images_validation, \n",
    "                                          shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          batch_size=16 #how many images per batch\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functional API version of the model\n",
    "\n",
    "inputs = Input((image_size, image_size, 1))\n",
    "conv1 = Conv2D(64, (5,5), padding='same', strides=2)(inputs)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "conv1 = Activation('relu')(conv1)\n",
    "#conv1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3,3), padding='same', strides=1)(conv1)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Activation('relu')(conv2)\n",
    "\n",
    "conv3 = Conv2D(64, (3,3), padding='same', strides=2)(conv2)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = Activation('relu')(conv3)\n",
    "#conv3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "\n",
    "conv4 = Conv2D(128, (3,3), padding='same')(conv3)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "conv4 = Activation('relu')(conv4)\n",
    "\n",
    "conv5 = Conv2D(128, (3,3), padding='same', strides=2)(conv4)\n",
    "conv5 = BatchNormalization()(conv5)\n",
    "conv5 = Activation('relu')(conv5)\n",
    "#conv5 = MaxPooling2D(pool_size=(2,2))(conv5)\n",
    "\n",
    "conv6 = Conv2D(256, (3,3), padding='same')(conv5)\n",
    "conv6 = BatchNormalization()(conv6)\n",
    "conv6 = Activation('relu')(conv6)\n",
    "\n",
    "conv7 = Conv2D(256, (3,3), padding='same', strides=2)(conv6)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "conv7 = Activation('relu')(conv7)\n",
    "#conv7 = MaxPooling2D(pool_size=(2,2))(conv7)\n",
    "\n",
    "conv8 = Conv2D(512, (3,3), padding='same')(conv7)\n",
    "conv8 = BatchNormalization()(conv8)\n",
    "conv8 = Activation('relu')(conv8)\n",
    "\n",
    "conv9 = Conv2D(512, (3,3), padding='same', strides=2)(conv8)\n",
    "conv9 = BatchNormalization()(conv9)\n",
    "conv9 = Activation('relu')(conv9)\n",
    "#conv9 = MaxPooling2D(pool_size=(2,2))(conv9)\n",
    "\n",
    "conv10 = Conv2D(1024, (3,3), padding='same', strides=2)(conv9)\n",
    "conv10 = BatchNormalization()(conv10)\n",
    "conv10 = Activation('relu')(conv10)\n",
    "conv10 = MaxPooling2D(pool_size=(2,2))(conv10)\n",
    "\n",
    "flat = Flatten()(conv10)\n",
    "flat = Dense(1000)(flat)\n",
    "flat = Activation('relu')(flat)\n",
    "flat = Dropout(0.35)(flat)\n",
    "flat = Dense(250)(flat)\n",
    "flat = Activation('relu')(flat)\n",
    "\n",
    "\n",
    "finish = Dropout(0.35)(flat)\n",
    "finish = Dense(number_of_categories)(finish)\n",
    "finish = Activation('softmax')(finish)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[finish])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, decay=.00001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'],\n",
    "             )\n",
    "\n",
    "print(model.count_params())\n",
    "print(model.summary())\n",
    "\n",
    "temp_class_weights = get_class_weights(photos.classes, 0.1)\n",
    "num_images = len(photos.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(photos, \n",
    "                    #steps_per_epoch=200,\n",
    "                    steps_per_epoch=num_images/16,\n",
    "                    epochs=10,\n",
    "                    initial_epoch=0,\n",
    "                    validation_data = photos_validation,\n",
    "                    validation_steps = 600,\n",
    "                    class_weight=temp_class_weights,  #this is to help with the unbalanced class issue\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('path/to/models/CNN_model_mdl3.mdl')\n",
    "model.save_weights('path/to/model/weights/CNN_model_weights_mdl3.wts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(home_path + 'models/CNN_model_mdl3.mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "photos_confusion.reset()\n",
    "Y_pred = model.predict_generator(photos_confusion, num_images/16 + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "num_images = len(photos_confusion.classes)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(photos_confusion.classes, y_pred[:num_images]))\n",
    "check_answer = sort(list(photos_confusion.class_indices))\n",
    "print('Classification Report')\n",
    "target_names = check_answer\n",
    "print(classification_report(photos_confusion.classes, y_pred[:num_images], target_names=target_names))\n",
    "conf_mat = pd.DataFrame(confusion_matrix(photos_confusion.classes, y_pred[:num_images]), columns=target_names, index=target_names)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figsize(20, 20)\n",
    "sns.heatmap(conf_mat.divide(conf_mat.sum()+1), vmax=1, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos_validation_confusion.reset()\n",
    "Y_pred = model.predict_generator(photos_validation_confusion, num_images/16 + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "num_images = len(photos_validation_confusion.classes)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(photos_validation_confusion.classes, y_pred[:num_images]))\n",
    "check_answer = sort(list(photos_validation_confusion.class_indices))\n",
    "print('Classification Report')\n",
    "target_names = check_answer\n",
    "print(classification_report(photos_validation_confusion.classes, y_pred[:num_images], target_names=target_names))\n",
    "conf_mat = pd.DataFrame(confusion_matrix(photos_validation_confusion.classes, y_pred[:num_images]), columns=target_names, index=target_names)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figsize(20, 20)\n",
    "sns.heatmap(conf_mat.divide(conf_mat.sum()+1), vmax=1, cmap='binary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
