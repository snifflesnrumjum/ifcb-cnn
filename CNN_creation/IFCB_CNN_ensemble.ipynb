{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will use IFCB images to train a convolutional neural network and have it classify images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, ZeroPadding2D, Input\n",
    "from keras.layers import concatenate\n",
    "from keras.preprocessing import image as keras_image\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import tf as ktf\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Add, Multiply, Concatenate, Average\n",
    "\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "from collections import Counter\n",
    "import os\n",
    "import skimage.transform as ski_transform\n",
    "import skimage.io as ski_io\n",
    "from skimage import img_as_float\n",
    "\n",
    "\n",
    "from PIL import Image as PIL_Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "import ROI_image_reader_stitched as ROI\n",
    "import shutil\n",
    "import pickle\n",
    "import ROI_image_reader_stitched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = 'F:/IFCB/'\n",
    "out_folder_of_images = home_path + 'Training_sets_padded/'  #path to the padded images from the training set\n",
    "out_folder_of_images_unpadded = home_path + 'Training_sets_unpadded/' #path to the unpadded images from the training set\n",
    "folder_of_images_validation = home_path + 'validation_sets/' #where to put the validation sets\n",
    "\n",
    "number_of_categories = 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_background(image):\n",
    "    shape = image.shape\n",
    "    mid = int(shape[0] / 2)\n",
    "    bkgd_mean = image[mid,:].mean()\n",
    "    bkgd_std = image[mid, :].std()\n",
    "    image -= bkgd_mean\n",
    "    image /= (bkgd_std+0.001)\n",
    "    \n",
    "    image *= -1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image size\n",
    "image_size = 300  #an X by X size square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move validation set back into main set\n",
    "photos = os.walk(folder_of_images_validation)\n",
    "\n",
    "for files in photos:\n",
    "    print(files[0])\n",
    "    outdir = files[0].split('/')[-1]\n",
    "    for picture in files[2]:\n",
    "        if picture[-3:] == 'png' or picture[-3:] == 'tif':\n",
    "            #print(picture)\n",
    "            shutil.move(files[0]+'/'+picture, out_folder_of_images + outdir + '/' + picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a validation dataset\n",
    "import shutil\n",
    "photos = os.walk(out_folder_of_images)\n",
    "\n",
    "num_photo = 0\n",
    "for files in photos:\n",
    "    print(files[0])\n",
    "    outdir = files[0].split('/')[-1]\n",
    "    if outdir not in os.listdir(folder_of_images_validation) and outdir != '':\n",
    "        os.mkdir('{0}/{1}'.format(folder_of_images_validation, outdir))\n",
    "    for picture in files[2][0::5]:\n",
    "        if picture[-3:] == 'png' or picture[-3:] == 'tif':\n",
    "            #print(picture)\n",
    "            num_photo += 1\n",
    "            shutil.move(files[0]+'/'+picture, folder_of_images_validation + outdir + '/' + picture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training data generator\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos = keras_image.ImageDataGenerator(#rotation_range=10,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        horizontal_flip=True, #flip images horizontally\n",
    "                                        vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        #samplewise_std_normalization=True,\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.1,\n",
    "                                        #featurewise_center=True,\n",
    "                                        #featurewise_std_normalization=True\n",
    "                                       )\n",
    "\n",
    "#start the actual flow of images for training\n",
    "photos = input_photos.flow_from_directory(out_folder_of_images, \n",
    "                                          shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          batch_size=16,) #how many images per batch\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training data generator\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos_unpadded = keras_image.ImageDataGenerator(#rotation_range=10,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        horizontal_flip=True, #flip images horizontally\n",
    "                                        vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        #samplewise_std_normalization=True,\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.1,\n",
    "                                        #featurewise_center=True,\n",
    "                                        #featurewise_std_normalization=True\n",
    "                                       )\n",
    "\n",
    "#start the actual flow of images for training\n",
    "photos_unpadded = input_photos_unpadded.flow_from_directory(out_folder_of_images_unpadded, \n",
    "                                          shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          batch_size=16,) #how many images per batch\n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#validation data generator\n",
    "\n",
    "#folder_of_images_validation = '/home/campbelllab/IFCB/IFCB_Conv_NN/validation_sets_size_300/'  #images for training\n",
    "\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos_validation = keras_image.ImageDataGenerator(#rotation_range=10,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        #width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        horizontal_flip=True, #flip images horizontally\n",
    "                                        vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation[constant, wrap, reflect, nearest]\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.1,\n",
    "                                        \n",
    "                                        )\n",
    "#start the actual flow of images for training\n",
    "photos_validation = input_photos_validation.flow_from_directory(folder_of_images_validation, \n",
    "                                          #shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          #save_to_dir='D:/Python27/Projects/Classifiers/augmented_data/',\n",
    "                                          batch_size=16) #how many images per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix data generator\n",
    "\n",
    "#adding some modifications to allow for data augmentation (images are manipulated some to make more instances of training data)\n",
    "input_photos_confusion = keras_image.ImageDataGenerator(#rotation_range=10.,  #allow images to be rotated randomly between 0 and 90 degrees\n",
    "                                        #width_shift_range=5, #randomly shift image this fraction of total width\n",
    "                                        #height_shift_range=5, #randomly shift image this fraction of total height\n",
    "                                        #horizontal_flip=True, #flip images horizontally\n",
    "                                        #vertical_flip=True, #flip images vertically\n",
    "                                        fill_mode='nearest', #how to fill in empty space after shift/rotation[constant, wrap, reflect, nearest]\n",
    "                                        #cval=128, #fill value for fill_mode\n",
    "                                        preprocessing_function=eliminate_background,\n",
    "                                        rescale = 1/255.,\n",
    "                                        #zoom_range = 0.15,\n",
    "                                        )\n",
    "#start the actual flow of images for training\n",
    "photos_confusion = input_photos_confusion.flow_from_directory(out_folder_of_images, \n",
    "                                          shuffle=False,\n",
    "                                          color_mode='grayscale', #all ifcb images are grayscale\n",
    "                                          class_mode='categorical', #there are multiple classes of images (i.e. > 2)\n",
    "                                          target_size=(image_size,image_size),  #squish/stretch images to this size\n",
    "                                          batch_size=16 #how many images per batch\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Okay the images are all ready to be loaded and will be resized to a 300x300 image (I can change this in the #ImageDataGenerator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_images = len(photos.classes)\n",
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try this function to correct for imbalanced classes \n",
    "#downloaded this function code from: https://github.com/cbaziotis/keras-utilities/blob/master/kutilities/helpers/data_preparation.py\n",
    "def get_class_weights(y, smooth_factor=0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    return {cls: float(majority) / count for cls, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_class_weights = get_class_weights(photos.classes, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start the training of the ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move validation set back into main set\n",
    "photos = os.walk(folder_of_images_validation)\n",
    "\n",
    "for files in photos:\n",
    "    print(files[0])\n",
    "    outdir = files[0].split('/')[-1]\n",
    "    for picture in files[2]:\n",
    "        if picture[-3:] == 'png' or picture[-3:] == 'tif':\n",
    "            #print(picture)\n",
    "            shutil.move(files[0]+'/'+picture, out_folder_of_images + outdir + '/' + picture)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_models = '/path/to/models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all three models if possible\n",
    "#combine them into one single ensemble model\n",
    "#make each individual model untrainable\n",
    "#train a final layer for weighting the individual models\n",
    "\n",
    "model1 = load_model(path_to_models + 'CNN_model_mdl1_padded.mdl')\n",
    "model1.trainable = False\n",
    "\n",
    "model2 = load_model(path_to_models + 'CNN_model_mdl2_padded.mdl')\n",
    "model2.trainable = False\n",
    "\n",
    "model3 = load_model(path_to_models + 'CNN_model_mdl3_padded.mdl')\n",
    "model3.trainable = False\n",
    "\n",
    "model4 = load_model(path_to_models + 'CNN_model_mdl1_unpadded.mdl')\n",
    "model4.trainable = False\n",
    "\n",
    "model5 = load_model(path_to_models + 'CNN_model_mdl2_unpadded.mdl')\n",
    "model5.trainable = False\n",
    "\n",
    "model6 = load_model(path_to_models + 'CNN_model_mdl3_unpadded.mdl')\n",
    "model6.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the model layers so they don't conflict with each other\n",
    "\n",
    "for num, layer in enumerate(model1.layers):\n",
    "    layer.name = 'Model1_'+str(num)\n",
    "model1.name = 'Model1'\n",
    "\n",
    "for num, layer in enumerate(model2.layers):\n",
    "    layer.name = 'Model2_'+str(num)\n",
    "model2.name =  'Model2'\n",
    "\n",
    "for num, layer in enumerate(model3.layers):\n",
    "    layer.name = 'Model3_'+str(num)\n",
    "model3.name = 'Model3'\n",
    "\n",
    "for num, layer in enumerate(model4.layers):\n",
    "    layer.name = 'Model4_'+str(num)\n",
    "model4.name = 'Model4'\n",
    "\n",
    "for num, layer in enumerate(model5.layers):\n",
    "    layer.name = 'Model5_'+str(num)\n",
    "model5.name =  'Model5'\n",
    "\n",
    "for num, layer in enumerate(model6.layers):\n",
    "    layer.name = 'Model6_'+str(num)\n",
    "model6.name = 'Model6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_inputs = Input((image_size, image_size, 1))\n",
    "unpadded_inputs = Input((image_size, image_size, 1))\n",
    "\n",
    "out1 = model1(padded_inputs)\n",
    "out2 = model2(padded_inputs)\n",
    "out3 = model3(padded_inputs)\n",
    "out4 = model4(unpadded_inputs)\n",
    "out5 = model5(unpadded_inputs)\n",
    "out6 = model6(unpadded_inputs)\n",
    "\n",
    "test = Concatenate()([out1, out2, out3, out4, out5, out6])\n",
    "test = Dense(112, name='model_ensemble_3')(test)\n",
    "test = Activation('softmax', name='model_ensemble_4')(test)\n",
    "\n",
    "ensemble = Model([padded_inputs, unpadded_inputs], test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.00001, decay=.000001)\n",
    "ensemble.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos.reset()\n",
    "photos_unpadded.reset()\n",
    "num_images = len(photos.classes)\n",
    "temp_class_weights = get_class_weights(photos.classes, 0.1)\n",
    "\n",
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_batches(num_batches=6795):\n",
    "    padded = []\n",
    "    unpadded = []\n",
    "    answers = []\n",
    "    for x in range(num_batches):\n",
    "        if x % 50 == 0:\n",
    "            print(x, end=',')\n",
    "        temp1 = photos.next()\n",
    "        temp2 = photos_unpadded.next()\n",
    "        padded.extend(temp1[0])\n",
    "        unpadded.extend(temp2[0])\n",
    "        answers.extend(temp1[1])\n",
    "    \n",
    "    return [padded, unpadded, answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_batch_generator():\n",
    "    \n",
    "    while 1:\n",
    "        temp1 = photos.next()\n",
    "        temp2 = photos_unpadded.next()\n",
    "        \n",
    "    \n",
    "        yield [[temp1[0], temp2[0]], temp1[1]]\n",
    "        \n",
    "    return\n",
    "\n",
    "def get_image_batch_generator_prediction():\n",
    "    \n",
    "    while 1:\n",
    "        temp1 = photos.next()\n",
    "        temp2 = photos_unpadded.next()\n",
    "        \n",
    "    \n",
    "        yield [temp1[0], temp2[0]]\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_padded, in_unpadded, answers = get_image_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = ensemble.fit_generator(get_image_batch_generator(),\n",
    "                    steps_per_epoch=int(num_images/16),\n",
    "                    epochs=3,\n",
    "                    initial_epoch=0,\n",
    "                    #validation_data = photos_validation,\n",
    "                    #validation_steps = 600,\n",
    "                    class_weight=temp_class_weights,  #this is to help with the unbalanced class issue\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the ensemble model\n",
    "ensemble.save_weights(path_to_models + 'ensemble_model__weights.wts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the ensemble model\n",
    "#use this when needed for testing or reloading the model\n",
    "ensemble.load_weights(path_to_models + 'ensemble_model_weights.wts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos.reset()\n",
    "photos_unpadded.reset()\n",
    "num_images = len(photos.classes)\n",
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "photos_confusion.reset()\n",
    "Y_pred = ensemble.predict_generator(get_image_batch_generator_prediction(), num_images/16 + 1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(photos_confusion.classes, y_pred[:num_images]))\n",
    "check_answer = sort(list(photos_confusion.class_indices))\n",
    "print('Classification Report')\n",
    "target_names = check_answer\n",
    "print(classification_report(photos_confusion.classes, y_pred[:num_images], target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conf_mat = pd.DataFrame(confusion_matrix(photos_confusion.classes, y_pred[:num_images]), columns=target_names, index=target_names)\n",
    "conf_mat['Asterionellopsis'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figsize(20, 20)\n",
    "sns.heatmap(conf_mat.divide(conf_mat.sum()+1), vmax=1,cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[] for x in range(112)]\n",
    "photos.reset()\n",
    "photos_unpadded.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = get_image_batch_generator()\n",
    "for z in range(7574):\n",
    "    ims = next(imgs)\n",
    "    res = ensemble.predict_on_batch(ims[0])\n",
    "\n",
    "    for x,y in enumerate(res):\n",
    "        results[ims[1][x].argmax()].append(res[x][ims[1][x].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(112):\n",
    "    temp = np.array(results[x])\n",
    "    print('Category:', check_answer[x])\n",
    "    print('avg:', temp.mean())\n",
    "    print('std:', temp.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [np.array(temp).mean() - 3*np.array(temp).std() for temp in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the thresholds to a file so that they can be loaded later\n",
    "with open('/path/to/models/thresholds_ensemble.pck', 'wb') as f:\n",
    "    pickle.dump(thresholds, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the probability results in case we want to change our threshold later\n",
    "with open('/path/to/models/prob_scores_ensemble.pck', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the probability results in case we want to change our threshold later\n",
    "with open('/path/to/models/thresholds_ensemble.pck', 'rb') as f:\n",
    "    thresholds = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(check_answer[x], thresholds[x]) for x in range(112)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
